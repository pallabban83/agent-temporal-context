"""
Comprehensive test suite for PDFs generated by generate_test_pdfs.py.

Tests validate:
1. Table detection and extraction (has_tables, total_tables, pages_with_tables)
2. Multi-page PDF handling (correct page numbers, chunk distribution)
3. Empty pages handling (non_empty_pages metadata accuracy)
4. Large table atomicity (tables > chunk_size kept intact, quality scoring)
5. Table-aware chunking (no mid-table splits, complete [TABLE N]...[END TABLE])
6. Temporal extraction from tables (quarters, dates in table cells)
7. Mixed content handling (tables interleaved with text)
8. Global table numbering (sequential across pages, not per-page)

Prerequisites:
    Run generate_test_pdfs.py first to create the test PDFs

Run:
    python test_generated_pdf_validation.py
"""

import sys
import os
from pathlib import Path
from datetime import datetime
import re

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from temporal_embeddings import TemporalEmbeddingHandler
from document_parser import DocumentParser
from text_chunker import TextChunker


def test_single_table_pdf():
    """Test PDF with a single table - Q2_2024_Earnings_With_Table.pdf"""

    print("=" * 100)
    print("TEST 1: SINGLE TABLE PDF - Q2_2024_Earnings_With_Table.pdf")
    print("=" * 100)
    print()

    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    test_file = test_pdfs_dir / "Q2_2024_Earnings_With_Table.pdf"

    if not test_file.exists():
        print(f"‚ùå Test file not found: {test_file}")
        print(f"   Run generate_test_pdfs.py first to create test PDFs")
        return False

    print(f"Testing: {test_file.name}\n")

    # Parse PDF
    with open(test_file, 'rb') as f:
        file_bytes = f.read()

    pdf_result = DocumentParser.parse_pdf_by_pages(file_bytes)

    # Test 1: Table detection metadata
    print("TABLE DETECTION METADATA:")
    print("-" * 100)

    tests_passed = []

    has_tables = pdf_result.get('has_tables', False)
    total_tables = pdf_result.get('total_tables', 0)
    pages_with_tables = pdf_result.get('pages_with_tables', [])

    print(f"  has_tables:        {has_tables}")
    print(f"  total_tables:      {total_tables}")
    print(f"  pages_with_tables: {pages_with_tables}")
    print()

    # Validate
    tests_passed.append(("has_tables is True", has_tables == True))
    tests_passed.append(("total_tables >= 1", total_tables >= 1))
    tests_passed.append(("pages_with_tables not empty", len(pages_with_tables) > 0))

    # Test 2: Table content in markdown
    print("TABLE CONTENT VALIDATION:")
    print("-" * 100)

    page_texts = pdf_result.get('page_texts', [])
    combined_text = '\n'.join(page_texts)

    has_table_marker = '[TABLE 1]' in combined_text
    has_end_table_marker = '[END TABLE]' in combined_text

    print(f"  Contains [TABLE 1]:    {has_table_marker}")
    print(f"  Contains [END TABLE]:  {has_end_table_marker}")
    print()

    tests_passed.append(("[TABLE 1] marker present", has_table_marker))
    tests_passed.append(("[END TABLE] marker present", has_end_table_marker))

    # Test 3: Temporal extraction from table
    print("TEMPORAL EXTRACTION FROM TABLE:")
    print("-" * 100)

    handler = TemporalEmbeddingHandler(project_id="test-project", location="us-central1")
    temporal_entities = handler.extract_temporal_info(combined_text)

    # Extract fiscal quarters from the entity list
    fiscal_quarters = [e['value'] for e in temporal_entities if e['type'] == 'fiscal_quarter']
    has_q2_2024 = 'Q2 2024' in fiscal_quarters
    has_q1_2024 = 'Q1 2024' in fiscal_quarters

    print(f"  Fiscal quarters found: {len(fiscal_quarters)}")
    print(f"  Sample quarters:       {fiscal_quarters[:3] if fiscal_quarters else 'None'}")
    print(f"  Includes Q2 2024:      {has_q2_2024}")
    print(f"  Includes Q1 2024:      {has_q1_2024}")
    print()

    tests_passed.append(("Extracted fiscal quarters", len(fiscal_quarters) > 0))
    tests_passed.append(("Found Q2 2024", has_q2_2024))

    # Test 4: Table-aware chunking
    print("TABLE-AWARE CHUNKING:")
    print("-" * 100)

    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    base_metadata = {'filename': test_file.name, 'document_type': 'pdf'}
    chunks = chunker.chunk_pdf_by_pages(
        page_texts=page_texts,
        metadata=base_metadata,
        document_id="test_single_table"
    )

    print(f"  Total chunks created:  {len(chunks)}")

    # Check for table integrity (no split tables)
    split_tables_found = False
    for i, chunk in enumerate(chunks):
        content = chunk['content']
        table_starts = content.count('[TABLE')
        table_ends = content.count('[END TABLE]')

        if table_starts != table_ends:
            print(f"  ‚ùå Chunk {i}: Split table detected (starts={table_starts}, ends={table_ends})")
            split_tables_found = True

    if not split_tables_found:
        print(f"  ‚úì No split tables detected")

    tests_passed.append(("No split tables", not split_tables_found))

    # Check table metadata in chunks
    chunks_with_tables = [c for c in chunks if c['metadata'].get('has_table', False)]
    print(f"  Chunks with tables:    {len(chunks_with_tables)}")

    if chunks_with_tables:
        chunk = chunks_with_tables[0]
        meta = chunk['metadata']
        print(f"  - has_table:           {meta.get('has_table')}")
        print(f"  - table_count:         {meta.get('table_count')}")
        print(f"  - has_complete_table:  {meta.get('has_complete_table')}")

        tests_passed.append(("Chunk has_table metadata", meta.get('has_table') == True))
        tests_passed.append(("Chunk has_complete_table", meta.get('has_complete_table') == True))

    print()

    # Summary
    print("=" * 100)
    print("TEST RESULTS:")
    print("-" * 100)

    all_passed = True
    for test_name, passed in tests_passed:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
        if not passed:
            all_passed = False

    print()
    print(f"Overall: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 100)
    print()

    return all_passed


def test_multipage_pdf():
    """Test multi-page PDF with tables on different pages - Multi_Page_Report_2024.pdf"""

    print("=" * 100)
    print("TEST 2: MULTI-PAGE PDF - Multi_Page_Report_2024.pdf")
    print("=" * 100)
    print()

    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    test_file = test_pdfs_dir / "Multi_Page_Report_2024.pdf"

    if not test_file.exists():
        print(f"‚ùå Test file not found: {test_file}")
        return False

    print(f"Testing: {test_file.name}\n")

    # Parse PDF
    with open(test_file, 'rb') as f:
        file_bytes = f.read()

    pdf_result = DocumentParser.parse_pdf_by_pages(file_bytes)

    tests_passed = []

    # Test 1: Multi-page metadata
    print("MULTI-PAGE METADATA:")
    print("-" * 100)

    total_pages = pdf_result.get('total_pages', 0)
    non_empty_pages = pdf_result.get('non_empty_pages', 0)
    has_tables = pdf_result.get('has_tables', False)
    total_tables = pdf_result.get('total_tables', 0)
    pages_with_tables = pdf_result.get('pages_with_tables', [])

    print(f"  total_pages:        {total_pages}")
    print(f"  non_empty_pages:    {non_empty_pages}")
    print(f"  has_tables:         {has_tables}")
    print(f"  total_tables:       {total_tables}")
    print(f"  pages_with_tables:  {pages_with_tables}")
    print()

    tests_passed.append(("Has 5 pages", total_pages >= 5))
    tests_passed.append(("Has multiple tables", total_tables >= 2))
    tests_passed.append(("Multiple pages with tables", len(pages_with_tables) >= 2))

    # Test 2: Global table numbering (not per-page)
    print("GLOBAL TABLE NUMBERING:")
    print("-" * 100)

    page_texts = pdf_result.get('page_texts', [])
    combined_text = '\n'.join(page_texts)

    # Find all table markers
    table_markers = re.findall(r'\[TABLE (\d+)\]', combined_text)
    table_numbers = [int(n) for n in table_markers]

    print(f"  Table markers found: {table_numbers}")

    # Validate sequential numbering (1, 2, 3, ...)
    is_sequential = table_numbers == list(range(1, len(table_numbers) + 1))
    print(f"  Sequential numbering: {is_sequential}")

    # Validate no duplicate numbers (global, not per-page)
    has_duplicates = len(table_numbers) != len(set(table_numbers))
    print(f"  No duplicate numbers: {not has_duplicates}")
    print()

    tests_passed.append(("Sequential table numbering", is_sequential))
    tests_passed.append(("No duplicate table numbers", not has_duplicates))

    # Test 3: Chunking with page distribution
    print("CHUNKING ACROSS PAGES:")
    print("-" * 100)

    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    base_metadata = {'filename': test_file.name, 'document_type': 'pdf', 'total_pages': total_pages}
    chunks = chunker.chunk_pdf_by_pages(
        page_texts=page_texts,
        metadata=base_metadata,
        document_id="test_multipage"
    )

    print(f"  Total chunks:        {len(chunks)}")

    # Check page number distribution
    page_numbers = [c['metadata'].get('page_number') for c in chunks if 'page_number' in c['metadata']]
    unique_pages = sorted(set(page_numbers))

    print(f"  Pages represented:   {unique_pages}")
    print(f"  All pages chunked:   {len(unique_pages) >= total_pages - 1}")  # Allow for potential empty pages
    print()

    tests_passed.append(("Multiple chunks created", len(chunks) > 1))
    tests_passed.append(("Multiple pages represented", len(unique_pages) > 1))

    # Test 4: Table integrity across pages
    print("TABLE INTEGRITY:")
    print("-" * 100)

    split_tables = 0
    for i, chunk in enumerate(chunks):
        content = chunk['content']
        table_starts = content.count('[TABLE')
        table_ends = content.count('[END TABLE]')

        if table_starts != table_ends:
            split_tables += 1

    print(f"  Split tables found:  {split_tables}")
    tests_passed.append(("No split tables", split_tables == 0))
    print()

    # Summary
    print("=" * 100)
    print("TEST RESULTS:")
    print("-" * 100)

    all_passed = True
    for test_name, passed in tests_passed:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
        if not passed:
            all_passed = False

    print()
    print(f"Overall: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 100)
    print()

    return all_passed


def test_large_table_pdf():
    """Test PDF with large table exceeding chunk_size - Large_Table_Monthly_Data_2024.pdf"""

    print("=" * 100)
    print("TEST 3: LARGE TABLE PDF - Large_Table_Monthly_Data_2024.pdf")
    print("=" * 100)
    print()

    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    test_file = test_pdfs_dir / "Large_Table_Monthly_Data_2024.pdf"

    if not test_file.exists():
        print(f"‚ùå Test file not found: {test_file}")
        return False

    print(f"Testing: {test_file.name}\n")

    # Parse PDF
    with open(test_file, 'rb') as f:
        file_bytes = f.read()

    pdf_result = DocumentParser.parse_pdf_by_pages(file_bytes)
    page_texts = pdf_result.get('page_texts', [])
    combined_text = '\n'.join(page_texts)

    tests_passed = []

    # Test 1: Find the large table
    print("LARGE TABLE DETECTION:")
    print("-" * 100)

    # Extract table content
    table_match = re.search(r'\[TABLE \d+\](.*?)\[END TABLE\]', combined_text, re.DOTALL)

    if table_match:
        table_content = table_match.group(0)
        table_size = len(table_content)

        print(f"  Table found:         Yes")
        print(f"  Table size:          {table_size} characters")
        print(f"  Exceeds 1000 chars:  {table_size > 1000}")
        print(f"  Exceeds 2000 chars:  {table_size > 2000}")
        print()

        tests_passed.append(("Large table detected", table_size > 1000))
    else:
        print(f"  ‚ùå No table found in PDF")
        return False

    # Test 2: Atomic table chunking (table kept intact)
    print("ATOMIC TABLE CHUNKING:")
    print("-" * 100)

    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    base_metadata = {'filename': test_file.name, 'document_type': 'pdf'}
    chunks = chunker.chunk_pdf_by_pages(
        page_texts=page_texts,
        metadata=base_metadata,
        document_id="test_large_table"
    )

    print(f"  Total chunks:        {len(chunks)}")

    # Find chunk containing the table
    table_chunk = None
    for i, chunk in enumerate(chunks):
        if '[TABLE 1]' in chunk['content'] and '[END TABLE]' in chunk['content']:
            table_chunk = chunk
            chunk_index = i
            break

    if table_chunk:
        chunk_size = len(table_chunk['content'])
        quality_score = table_chunk['metadata'].get('quality_score', 0)

        print(f"  Table chunk index:   {chunk_index}")
        print(f"  Chunk size:          {chunk_size} characters")
        print(f"  Chunk exceeds 1000:  {chunk_size > 1000}")
        print(f"  Quality score:       {quality_score:.3f}")
        print(f"  Table kept atomic:   {chunk_size > 1000}")  # If > 1000, table wasn't split
        print()

        tests_passed.append(("Table kept atomic", chunk_size > 1000))
        tests_passed.append(("Quality score assigned", quality_score > 0))

        # Test 3: Verify no split tables
        table_starts = table_chunk['content'].count('[TABLE')
        table_ends = table_chunk['content'].count('[END TABLE]')

        print(f"  Table starts in chunk:  {table_starts}")
        print(f"  Table ends in chunk:    {table_ends}")
        print(f"  Balanced markers:       {table_starts == table_ends}")
        print()

        tests_passed.append(("No split table", table_starts == table_ends))
    else:
        print(f"  ‚ùå Table not found in chunks")
        return False

    # Test 4: Temporal extraction from large table
    print("TEMPORAL EXTRACTION FROM LARGE TABLE:")
    print("-" * 100)

    handler = TemporalEmbeddingHandler(project_id="test-project", location="us-central1")
    temporal_entities = handler.extract_temporal_info(combined_text)

    # Extract month-year entities from the list
    month_years = [e['value'] for e in temporal_entities if e['type'] == 'month_year']

    # Should find multiple months (January 2024, February 2024, etc.)
    months_2024 = [m for m in month_years if '2024' in m]

    print(f"  Month-year entries:  {len(month_years)}")
    print(f"  2024 months found:   {len(months_2024)}")
    print(f"  Sample entries:      {months_2024[:3] if months_2024 else 'None'}")
    print()

    tests_passed.append(("Multiple months extracted", len(months_2024) >= 10))

    # Summary
    print("=" * 100)
    print("TEST RESULTS:")
    print("-" * 100)

    all_passed = True
    for test_name, passed in tests_passed:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
        if not passed:
            all_passed = False

    print()
    print(f"Overall: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 100)
    print()

    return all_passed


def test_mixed_content_pdf():
    """Test PDF with mixed tables and text - Mixed_Content_Aug_2024.pdf"""

    print("=" * 100)
    print("TEST 4: MIXED CONTENT PDF - Mixed_Content_Aug_2024.pdf")
    print("=" * 100)
    print()

    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    test_file = test_pdfs_dir / "Mixed_Content_Aug_2024.pdf"

    if not test_file.exists():
        print(f"‚ùå Test file not found: {test_file}")
        return False

    print(f"Testing: {test_file.name}\n")

    # Parse PDF
    with open(test_file, 'rb') as f:
        file_bytes = f.read()

    pdf_result = DocumentParser.parse_pdf_by_pages(file_bytes)
    page_texts = pdf_result.get('page_texts', [])
    combined_text = '\n'.join(page_texts)

    tests_passed = []

    # Test 1: Mixed content detection
    print("MIXED CONTENT DETECTION:")
    print("-" * 100)

    total_tables = pdf_result.get('total_tables', 0)

    # Count text content (non-table text)
    # Remove table sections to measure pure text
    text_without_tables = re.sub(r'\[TABLE \d+\].*?\[END TABLE\]', '', combined_text, flags=re.DOTALL)
    text_word_count = len(text_without_tables.split())

    print(f"  Total tables:        {total_tables}")
    print(f"  Non-table words:     {text_word_count}")
    print(f"  Has both tables and text: {total_tables >= 2 and text_word_count > 50}")
    print()

    tests_passed.append(("Multiple tables present", total_tables >= 2))
    tests_passed.append(("Substantial text content", text_word_count > 50))

    # Test 2: Content interleaving
    print("CONTENT INTERLEAVING:")
    print("-" * 100)

    # Check if text appears before, between, and after tables
    sections = re.split(r'\[TABLE \d+\].*?\[END TABLE\]', combined_text, flags=re.DOTALL)
    sections_with_content = [s for s in sections if s.strip() and len(s.split()) > 5]

    print(f"  Text sections between tables: {len(sections_with_content)}")
    print(f"  Content properly interleaved: {len(sections_with_content) >= 2}")
    print()

    tests_passed.append(("Text interleaved with tables", len(sections_with_content) >= 2))

    # Test 3: Chunking with mixed content
    print("CHUNKING MIXED CONTENT:")
    print("-" * 100)

    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    base_metadata = {'filename': test_file.name, 'document_type': 'pdf'}
    chunks = chunker.chunk_pdf_by_pages(
        page_texts=page_texts,
        metadata=base_metadata,
        document_id="test_mixed"
    )

    print(f"  Total chunks:        {len(chunks)}")

    # Categorize chunks
    chunks_with_tables = [c for c in chunks if c['metadata'].get('has_table', False)]
    chunks_text_only = [c for c in chunks if not c['metadata'].get('has_table', False)]

    print(f"  Chunks with tables:  {len(chunks_with_tables)}")
    print(f"  Text-only chunks:    {len(chunks_text_only)}")
    print()

    tests_passed.append(("Mixed chunk types", len(chunks_with_tables) > 0 and len(chunks_text_only) > 0))

    # Test 4: Quality scores for different chunk types
    print("QUALITY SCORES BY CHUNK TYPE:")
    print("-" * 100)

    if chunks_with_tables:
        table_scores = [c['metadata'].get('quality_score', 0) for c in chunks_with_tables]
        avg_table_score = sum(table_scores) / len(table_scores)
        print(f"  Avg table chunk score:     {avg_table_score:.3f}")

    if chunks_text_only:
        text_scores = [c['metadata'].get('quality_score', 0) for c in chunks_text_only]
        avg_text_score = sum(text_scores) / len(text_scores)
        print(f"  Avg text-only chunk score: {avg_text_score:.3f}")

    print()

    tests_passed.append(("Quality scores assigned", all(c['metadata'].get('quality_score', 0) > 0 for c in chunks)))

    # Test 5: Temporal extraction from filename
    print("TEMPORAL EXTRACTION:")
    print("-" * 100)

    handler = TemporalEmbeddingHandler(project_id="test-project", location="us-central1")

    # Extract from filename
    filename = test_file.name
    extracted_date = handler.extract_date_from_filename(filename)

    print(f"  Filename:            {filename}")
    print(f"  Extracted date:      {extracted_date}")

    if extracted_date:
        normalized = handler._normalize_date(extracted_date)
        print(f"  Normalized:          {normalized}")
        print(f"  Expected Aug 2024:   {'2024-08' in normalized if normalized else False}")

        tests_passed.append(("Date extracted from filename", normalized and '2024-08' in normalized))

    print()

    # Summary
    print("=" * 100)
    print("TEST RESULTS:")
    print("-" * 100)

    all_passed = True
    for test_name, passed in tests_passed:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
        if not passed:
            all_passed = False

    print()
    print(f"Overall: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 100)
    print()

    return all_passed


def test_empty_pages_pdf():
    """Test PDF with empty pages - Report_With_Empty_Pages_2024.pdf"""

    print("=" * 100)
    print("TEST 5: EMPTY PAGES PDF - Report_With_Empty_Pages_2024.pdf")
    print("=" * 100)
    print()

    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    test_file = test_pdfs_dir / "Report_With_Empty_Pages_2024.pdf"

    if not test_file.exists():
        print(f"‚ùå Test file not found: {test_file}")
        return False

    print(f"Testing: {test_file.name}\n")

    # Parse PDF
    with open(test_file, 'rb') as f:
        file_bytes = f.read()

    pdf_result = DocumentParser.parse_pdf_by_pages(file_bytes)

    tests_passed = []

    # Test 1: Empty pages metadata
    print("EMPTY PAGES METADATA:")
    print("-" * 100)

    total_pages = pdf_result.get('total_pages', 0)
    non_empty_pages = pdf_result.get('non_empty_pages', 0)

    print(f"  total_pages:        {total_pages}")
    print(f"  non_empty_pages:    {non_empty_pages}")
    print(f"  Empty pages:        {total_pages - non_empty_pages}")
    print()

    # Expected: 5 total pages, 3 with content (pages 1, 3, 5)
    expected_total = 5
    expected_non_empty = 3

    tests_passed.append(("total_pages correct", total_pages == expected_total))
    tests_passed.append(("non_empty_pages correct", non_empty_pages == expected_non_empty))
    tests_passed.append(("Has empty pages", total_pages > non_empty_pages))

    # Test 2: Page texts array
    print("PAGE TEXTS ARRAY:")
    print("-" * 100)

    page_texts = pdf_result.get('page_texts', [])

    print(f"  Page texts count:   {len(page_texts)}")
    print(f"  Should equal non_empty_pages: {len(page_texts) == non_empty_pages}")
    print()

    # page_texts should only contain non-empty pages
    tests_passed.append(("page_texts count matches non_empty_pages", len(page_texts) == non_empty_pages))

    # Verify no empty strings in page_texts
    empty_page_texts = [i for i, p in enumerate(page_texts) if not p.strip()]
    print(f"  Empty strings in page_texts: {len(empty_page_texts)}")
    tests_passed.append(("No empty strings in page_texts", len(empty_page_texts) == 0))
    print()

    # Test 3: Chunking with metadata
    print("CHUNKING WITH EMPTY PAGES METADATA:")
    print("-" * 100)

    chunker = TextChunker(chunk_size=1000, chunk_overlap=200)
    base_metadata = {
        'filename': test_file.name,
        'document_type': 'pdf',
        'total_pages': total_pages,
        'non_empty_pages': non_empty_pages
    }

    chunks = chunker.chunk_pdf_by_pages(
        page_texts=page_texts,
        metadata=base_metadata,
        document_id="test_empty_pages"
    )

    print(f"  Total chunks:       {len(chunks)}")

    # Verify all chunks have the metadata
    if chunks:
        first_chunk_meta = chunks[0]['metadata']

        chunk_total_pages = first_chunk_meta.get('total_pages')
        chunk_non_empty = first_chunk_meta.get('non_empty_pages')

        print(f"  Chunk metadata:")
        print(f"    total_pages:      {chunk_total_pages}")
        print(f"    non_empty_pages:  {chunk_non_empty}")
        print()

        tests_passed.append(("Chunk has total_pages", chunk_total_pages == expected_total))
        tests_passed.append(("Chunk has non_empty_pages", chunk_non_empty == expected_non_empty))

    # Test 4: No empty chunks created
    print("CHUNK CONTENT VALIDATION:")
    print("-" * 100)

    empty_chunks = [i for i, c in enumerate(chunks) if not c['content'].strip()]

    print(f"  Empty chunks found: {len(empty_chunks)}")
    tests_passed.append(("No empty chunks", len(empty_chunks) == 0))
    print()

    # Summary
    print("=" * 100)
    print("TEST RESULTS:")
    print("-" * 100)

    all_passed = True
    for test_name, passed in tests_passed:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"  {status} - {test_name}")
        if not passed:
            all_passed = False

    print()
    print(f"Overall: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 100)
    print()

    return all_passed


def main():
    """Run all tests."""

    print()
    print("=" * 100)
    print("COMPREHENSIVE TEST SUITE FOR GENERATED PDFs")
    print("=" * 100)
    print()
    print("This test suite validates all features of the PDF processing pipeline:")
    print("  1. Table detection and extraction")
    print("  2. Multi-page handling with global table numbering")
    print("  3. Large table atomicity (no splitting)")
    print("  4. Mixed content (tables + text)")
    print("  5. Empty pages handling")
    print()
    print("Prerequisites: Run generate_test_pdfs.py first to create test PDFs")
    print("=" * 100)
    print()

    # Check if test PDFs exist
    test_pdfs_dir = Path(__file__).parent.parent / "test_pdfs"
    required_pdfs = [
        "Q2_2024_Earnings_With_Table.pdf",
        "Multi_Page_Report_2024.pdf",
        "Large_Table_Monthly_Data_2024.pdf",
        "Mixed_Content_Aug_2024.pdf",
        "Report_With_Empty_Pages_2024.pdf"
    ]

    missing_pdfs = [pdf for pdf in required_pdfs if not (test_pdfs_dir / pdf).exists()]

    if missing_pdfs:
        print("‚ùå MISSING TEST PDFs:")
        for pdf in missing_pdfs:
            print(f"   - {pdf}")
        print()
        print("Please run: python generate_test_pdfs.py")
        print()
        return False

    print("‚úì All test PDFs found")
    print()

    # Run tests
    test1 = test_single_table_pdf()
    test2 = test_multipage_pdf()
    test3 = test_large_table_pdf()
    test4 = test_mixed_content_pdf()
    test5 = test_empty_pages_pdf()

    # Overall summary
    print("=" * 100)
    print("OVERALL TEST SUMMARY")
    print("=" * 100)
    print(f"  Single table PDF:              {'‚úÖ PASS' if test1 else '‚ùå FAIL'}")
    print(f"  Multi-page PDF:                {'‚úÖ PASS' if test2 else '‚ùå FAIL'}")
    print(f"  Large table PDF:               {'‚úÖ PASS' if test3 else '‚ùå FAIL'}")
    print(f"  Mixed content PDF:             {'‚úÖ PASS' if test4 else '‚ùå FAIL'}")
    print(f"  Empty pages PDF:               {'‚úÖ PASS' if test5 else '‚ùå FAIL'}")
    print("=" * 100)

    all_passed = test1 and test2 and test3 and test4 and test5

    if all_passed:
        print()
        print("üéâ ‚úÖ ALL TESTS PASSED! üéâ")
        print()
        print("The PDF processing pipeline is working correctly:")
        print("  ‚úì Table detection and extraction")
        print("  ‚úì Global table numbering (sequential across pages)")
        print("  ‚úì Table-aware chunking (no mid-table splits)")
        print("  ‚úì Large table atomicity")
        print("  ‚úì Mixed content handling")
        print("  ‚úì Empty pages metadata")
        print("  ‚úì Quality scoring")
        print("  ‚úì Temporal extraction from tables")
        print()
    else:
        print()
        print("‚ùå SOME TESTS FAILED")
        print()
        print("Please review the test output above for details.")
        print()

    print("=" * 100)

    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
