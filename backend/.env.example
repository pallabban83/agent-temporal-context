# Google Cloud Configuration
# Uses Application Default Credentials (ADC) - run: gcloud auth application-default login
GOOGLE_CLOUD_PROJECT=your-gcp-project-id
GOOGLE_CLOUD_LOCATION=us-central1

# Vertex AI RAG Configuration
VERTEX_AI_CORPUS_NAME=temporal-context-corpus

# Vector Search Backend (Required for RAG Engine)
# You must create a Vector Search index with STREAM_UPDATE enabled first
# Format: projects/{PROJECT_NUMBER}/locations/{LOCATION}/indexes/{INDEX_ID}
VECTOR_SEARCH_INDEX=projects/123456789/locations/us-central1/indexes/1234567890
# Format: projects/{PROJECT_NUMBER}/locations/{LOCATION}/indexEndpoints/{ENDPOINT_ID}
VECTOR_SEARCH_INDEX_ENDPOINT=projects/123456789/locations/us-central1/indexEndpoints/1234567890

# GCS Bucket for Vector Search Index Storage
# If not specified, defaults to {project-id}-vector-search
GCS_BUCKET_NAME=your-gcs-bucket-name

# Embedding Model Configuration
# Options: text-embedding-005 (latest, recommended), text-embedding-004, text-multilingual-embedding-002
EMBEDDING_MODEL_NAME=text-embedding-005

# Embedding API Rate Limiting
# Maximum number of embedding requests per minute (to avoid quota errors)
EMBEDDING_REQUESTS_PER_MINUTE=60

# Vector Search Index Algorithm
# Options:
#   - brute_force: Fast deployment (2-5 min), exact search, good for <10K docs, uses e2-standard-2
#   - tree_ah: Slow deployment (30-60 min), approximate search, production scale, uses e2-standard-16
INDEX_ALGORITHM=brute_force

# Query Configuration
# Default number of results to return for queries (controlled by system, not LLM)
DEFAULT_TOP_K=20

# Logging Configuration
# Log format: "json" (structured JSON for production) or "logfmt" (key=value for development)
LOG_FORMAT=logfmt
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
# Enable colored output for logfmt format (auto-disabled if not a TTY)
LOG_COLORS=true
